{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-21T07:51:19.942450600Z",
     "start_time": "2025-04-21T07:51:19.916607500Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transformer Encoder Block结构是：\n",
    "```methamatica\n",
    "Input → MultiHeadSelfAttention → Add & Norm\n",
    "      → FeedForward → Add & Norm\n",
    "```\n",
    "\n",
    "原版实现使用的post-LN，但是有梯度消失、爆炸的隐患\n",
    "下面实现Pre-LN的结构，也就是LayerNorm放在其他子层输入之前"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "136e4a2f731adaa8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers.MultiHeadAttentijon import MultiHeadAttention\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_ff),   # Linear@x.shape=(batch_size, seq_len, d_model) → (batch_size, seq_len, dim_ff)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_ff, d_model)    # Linear@x.shape=(batch_size, seq_len, dim_ff) → (batch_size, seq_len, d_model)\n",
    "        )\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        # [size] x: (batch_size, seq_len, d_model)\n",
    "\n",
    "        # Pre-LN + Attention + Dropout + Residual\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, _ = self.attn(\n",
    "            x_norm,\n",
    "            padding_mask=padding_mask,\n",
    "            causal_mask=False\n",
    "        )\n",
    "        x = x + self.dropout1(attn_out)\n",
    "\n",
    "        # Pre-LN + FFN + Dropout + Residual\n",
    "        x_ffn = self.norm2(x)\n",
    "        ffn_out = self.ffn(x_ffn)\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "\n",
    "        return x  # (batch_size, seq_len, d_model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T07:51:19.943453400Z",
     "start_time": "2025-04-21T07:51:19.918822900Z"
    }
   },
   "id": "70535cec28605352",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "结构长这样\n",
    "```\n",
    "      Input (x)\n",
    "         │\n",
    "    ┌────┴────┐\n",
    "    ↓         ↓\n",
    " Self-Attn   Shortcut\n",
    "    ↓         ↓\n",
    " Dropout     │\n",
    "    ↓        │\n",
    "    Add ◄────┘\n",
    "     ↓  ────────       \n",
    " LayerNorm      │\n",
    "     ↓          │\n",
    " FeedForward    │\n",
    "     ↓          │\n",
    " Dropout        │   \n",
    "     ↓          │\n",
    " Add ◄──────────  \n",
    "     ↓     \n",
    " LayerNorm \n",
    "      ↓    \n",
    "   Output  \n",
    "\n",
    "\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ccb73467ca04004"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6, 512])\n",
      "Output shape: torch.Size([2, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "def test_encoder_block_pre_ln():\n",
    "    batch_size = 2\n",
    "    seq_len = 6\n",
    "    d_model = 512\n",
    "    num_heads = 8\n",
    "    dim_ff = 2048\n",
    "\n",
    "    # 模拟输入\n",
    "    x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "    # 模拟 padding mask（batch 中第 2 个序列有 3 个 padding）\n",
    "    padding_mask = torch.tensor([\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 1, 1]\n",
    "    ])  # shape: (batch_size, seq_len)\n",
    "\n",
    "    # 创建模块并测试\n",
    "    block = TransformerEncoderBlock(d_model=d_model, num_heads=num_heads, dim_ff=dim_ff)\n",
    "    out = block(x, padding_mask=padding_mask)\n",
    "\n",
    "    print(\"Input shape:\", x.shape)       # (2, 6, 512)\n",
    "    print(\"Output shape:\", out.shape)    # (2, 6, 512)\n",
    "\n",
    "test_encoder_block_pre_ln()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T07:51:32.870214300Z",
     "start_time": "2025-04-21T07:51:32.842684200Z"
    }
   },
   "id": "22c3ce177362e4d",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dim_ff, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderBlock(d_model, num_heads, dim_ff, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, padding_mask=padding_mask)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T07:55:05.165101100Z",
     "start_time": "2025-04-21T07:55:05.154588500Z"
    }
   },
   "id": "34f2ed5759ccef09",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 6, 512])\n",
      "Output shape: torch.Size([2, 6, 512])\n"
     ]
    }
   ],
   "source": [
    "def test_transformer_encoder():\n",
    "    batch_size = 2\n",
    "    seq_len = 6\n",
    "    d_model = 512\n",
    "    num_heads = 8\n",
    "    dim_ff = 2048\n",
    "    num_layers = 3\n",
    "\n",
    "    x = torch.randn(batch_size, seq_len, d_model)\n",
    "    padding_mask = torch.tensor([\n",
    "        [0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 1, 1, 1]\n",
    "    ])\n",
    "\n",
    "    encoder = TransformerEncoder(d_model, num_heads, dim_ff, num_layers)\n",
    "    out = encoder(x, padding_mask=padding_mask)\n",
    "\n",
    "    print(\"Input shape:\", x.shape)\n",
    "    print(\"Output shape:\", out.shape)\n",
    "test_transformer_encoder()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-21T07:55:16.875763500Z",
     "start_time": "2025-04-21T07:55:16.833494900Z"
    }
   },
   "id": "7089847cdd30106",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "38420c483868b6d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
