{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-17T21:10:00.062022300Z",
     "start_time": "2025-04-17T21:10:00.049986600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "先来看看BN的定义\n",
    "推荐视频:https://www.youtube.com/watch?v=BZh1ltr5Rkg\n",
    "$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Input:} \\text{ Values of } x \\text{ over a mini-batch: } \\mathcal{B} = \\{x_{1..m}\\}; \\\\\n",
    "\\quad \\quad \\quad \\text{ Parameters to be learned: } \\gamma, \\beta \\\\\n",
    "\\textbf{Output:} \\{y_i = \\text{BN}_{\\gamma,\\beta}(x_i)\\} \\\\\n",
    "\\\\\n",
    "\\mu_\\mathcal{B} \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m}x_i \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\text{// mini-batch mean} \\\\\n",
    "\\sigma_\\mathcal{B}^2 \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m}(x_i - \\mu_\\mathcal{B})^2 \\quad \\quad \\quad \\quad \\quad \\quad \\text{// mini-batch variance} \\\\\n",
    "\\hat{x}_i \\leftarrow \\frac{x_i - \\mu_\\mathcal{B}}{\\sqrt{\\sigma_\\mathcal{B}^2 + \\epsilon}} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\text{// normalize} \\\\\n",
    "y_i \\leftarrow \\gamma\\hat{x}_i + \\beta \\equiv \\text{BN}_{\\gamma,\\beta}(x_i) \\quad \\quad \\quad \\quad \\quad \\quad \\text{// scale and shift}\n",
    "\\end{array}\n",
    "$"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb4cf6477344c219"
  },
  {
   "cell_type": "markdown",
   "source": [
    "BN解决的问题有：\n",
    "1. improve gradient flow\n",
    "通过归一化每一层的输入，减少了internal covariate shift(较低层参数变动会导致后续层输入分布大幅变化)\n",
    "2. allow higher learning rates\n",
    "3. reduce strong dependence on initialization\n",
    "4. regularization\n",
    "要注意的的点有：\n",
    "1. 测试时均值与方差不再基于批次计算，而是基于训练期间的经验均值"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874619cc6ad8f970"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,) (20,)\n",
      "-0.18335136892609022 0.9809683438883487\n",
      "(100, 20) 3.552713678800501e-18 0.9999999989560583\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import BatchNorm2d\n",
    "np.random.seed(2025)\n",
    "# mini batch of x\n",
    "batch_size = 100\n",
    "features = 20\n",
    "x = np.random.randn(batch_size,features)\n",
    "x.shape\n",
    "\n",
    "# gamma and beta are learnable parameters\n",
    "def batch_normalization(x,gamma,beta,eps = 1e-9):\n",
    "    batch_mean = np.mean(x,axis=0) # shape (features,)\n",
    "    batch_var = np.var(x,axis=0) # shape (features,)\n",
    "    print(batch_mean.shape,batch_var.shape) \n",
    "    print(batch_mean[0],batch_var[0])\n",
    "    x_hat = (x - batch_mean) /  np.sqrt(batch_var+eps)\n",
    "    return gamma * x_hat + beta\n",
    "y = batch_normalization(x,1,0)\n",
    "print(y.shape,np.mean(y),np.var(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T21:10:00.072103600Z",
     "start_time": "2025-04-17T21:10:00.053022600Z"
    }
   },
   "id": "e55cce3bd323858",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "那么layer norm呢：\n",
    "$\n",
    "\\begin{array}{l}\n",
    "\\textbf{Input:} \\text{ 一个样本的特征向量: } \\mathcal{H} = \\{x_{1..H}\\}; \\\\\n",
    "\\quad \\quad \\quad \\text{ 需要学习的参数: } \\gamma, \\beta \\\\\n",
    "\\textbf{Output:} \\{y_i = \\text{LN}_{\\gamma,\\beta}(x_i)\\} \\\\\n",
    "\\\\\n",
    "\\mu_\\mathcal{H} \\leftarrow \\frac{1}{H}\\sum_{i=1}^{H}x_i \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad  \\quad \\quad \\text{// 特征维度均值} \\\\\n",
    "\\sigma_\\mathcal{H}^2 \\leftarrow \\frac{1}{H}\\sum_{i=1}^{H}(x_i - \\mu_\\mathcal{H})^2 \\quad \\quad \\quad \\quad \\quad \\quad \\text{// 特征维度方差} \\\\\n",
    "\\hat{x}_i \\leftarrow \\frac{x_i - \\mu_\\mathcal{H}}{\\sqrt{\\sigma_\\mathcal{H}^2 + \\epsilon}} \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\quad \\text{// 归一化} \\\\\n",
    "y_i \\leftarrow \\gamma\\hat{x}_i + \\beta \\equiv \\text{LN}_{\\gamma,\\beta}(x_i) \\quad \\quad \\quad \\quad \\quad \\quad \\text{// 缩放和偏移}\n",
    "\\end{array}\n",
    "\n",
    "$   "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd8fad13a425921a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1) (100, 1)\n",
      "[0.15872828] [1.11482916]\n",
      "(100, 20) -7.327471962526034e-18 0.9999999988190323\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(batch_size,features)\n",
    "def layer_normalization(x,gamma,beta,eps = 1e-9):\n",
    "    layer_mean = np.mean(x,axis=1,keepdims=True)\n",
    "    layer_var = np.var(x,axis=1,keepdims=True)\n",
    "    print(layer_mean.shape,layer_var.shape)\n",
    "    print(layer_mean[0],layer_var[0])\n",
    "    x_hat = (x - layer_mean) /  np.sqrt(layer_var+eps)\n",
    "    return gamma * x_hat + beta\n",
    "y = layer_normalization(x,np.ones((1,features)),np.zeros((1,features)))\n",
    "print(y.shape,np.mean(y),np.var(y))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-17T21:11:57.522197800Z",
     "start_time": "2025-04-17T21:11:57.519351400Z"
    }
   },
   "id": "1ff958a69397a392",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "代码上看起来区别只是axis 从0变成了1，但是仔细观察这两者的区别：\n",
    "axis = 0 是根据这个batch里某个feature所有的值进行normalization的\n",
    "axis = 1 是根据batch中的一个sample所有feature的均值进行normalization的"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a47f18e9c6f4d19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "BN vs LN\n",
    "BN适用于CNN,FNN，固定输入大小、较大批次训练的模型 ->较大批次的训练好产生可靠的均值和方差\n",
    "LN适用于RNN,Transformer或小批次变长序列处理模型。->使用单个样本内的统计信息，不受批次大小影响\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "938fd5a10015f7a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
